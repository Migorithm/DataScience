{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Data in DataFrames\n",
    "\n",
    "In this lecture we will learn how to manipulate data in dataframes. You will need these techniques to accomplish some of the following tasks:\n",
    "\n",
    " - Change data types when they are incorrectly interpretted\n",
    " - Clean your data\n",
    " - Create new columns\n",
    " - Rename columns\n",
    " - Extract or Create New Values\n",
    " \n",
    "We will also cover how to manipulate arrays in this lecture as well. \n",
    "\n",
    "#### So let's get started!\n",
    "\n",
    "First we will create our spark instance as we need to do at the start of every project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-JOJHKCD:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Manipulate</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x27779a49070>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Manipulate\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark's Immutability\n",
    "\n",
    "Before we get started, let's first take a moment to discuss the concept of Sparks Immutability. Spark DataFrames are immutable. What does that mean? Let's take a look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|   Abraham|  Lincoln|\n",
      "|    Coline|    Purse|\n",
      "+----------+---------+\n",
      "\n",
      "None\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "names= spark.createDataFrame([(\"Abraham\",\"Lincoln\"),(\"Coline\",\"Purse\")],[\"first_name\",\"last_name\"])\n",
    "\n",
    "print(names.show())\n",
    "print(names.rdd.id()) #each dataframe in spark has ID attatched to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dataframe id\n",
    "\n",
    "Now add a column to the dataframe and keep calling it the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a col\n",
    "from pyspark.sql.functions import *\n",
    "names = names.select(names.first_name,names.last_name,concat_ws(' ', names.first_name, names.last_name).alias('full_name'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see how the id of the dataframe changes but the name of the dataframe is still the same. So you can go back and reload the old id if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+\n",
      "|first_name|last_name|      full_name|\n",
      "+----------+---------+---------------+\n",
      "|   Abraham|  Lincoln|Abraham Lincoln|\n",
      "|    Coline|    Purse|   Coline Purse|\n",
      "+----------+---------+---------------+\n",
      "\n",
      "None\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(names.show())\n",
    "print(names.rdd.id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our Data Science Jobs DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../data/\"\n",
    "videos = spark.read.csv(path+'youtubevideos.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this dataset\n",
    "\n",
    "This dataset includes several months of data on daily trending YouTube videos.\n",
    "\n",
    "**Source:** https://www.kaggle.com/datasnaek/youtube-new#USvideos.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "\n",
       "  category_id              publish_time  \\\n",
       "0          22  2017-11-13T17:13:01.000Z   \n",
       "1          24  2017-11-13T07:30:00.000Z   \n",
       "2          23  2017-11-12T19:05:24.000Z   \n",
       "3          24  2017-11-13T11:00:04.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "\n",
       "  dislikes comment_count                                  thumbnail_link  \\\n",
       "0     2966         15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1     6146         12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2     5339          8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3      666          2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "\n",
       "  comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0             False            False                  False   \n",
       "1             False            False                  False   \n",
       "2             False            False                  False   \n",
       "3             False            False                  False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course the schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: string (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- dislikes: string (nullable = true)\n",
      " |-- comment_count: string (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: string (nullable = true)\n",
      " |-- ratings_disabled: string (nullable = true)\n",
      " |-- video_error_or_removed: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(videos.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we can see that a few of the variable types were not correctly infered. This is one of the common issues that you will run into in PySpark so in this lecture, we will learn how to correct it after the read in as opposed to during the read in. \n",
    "\n",
    "## Manipulate Data\n",
    "\n",
    "Being able to manipulate data is one of the most important skills for a data scientist to have whether you are doing machine learning or even simple reporting anlaytics. So will go over all the essentials here that you will need to do just that!\n",
    "\n",
    "*Note: Before you manipulate data, if you just want to test some code, you can use the .show() or .limit(6).toPandas() method as I've shown below. This will only display the results and NOT change your dataframe and also saves on computation time. *\n",
    "\n",
    "\n",
    "### Changing data types after read in\n",
    "First up, we see how to change data types. Many times, you will notice that Spark's \"handy\" infer schema is not quite so handy. So you'll end up needing to edit the data types after you read in a dataframe quite often. Here's how you do that.\n",
    "\n",
    "#### Available types:\n",
    "    - DataType\n",
    "    - NullType\n",
    "    - StringType\n",
    "    - BinaryType\n",
    "    - BooleanType\n",
    "    - DateType\n",
    "    - TimestampType\n",
    "    - DecimalType\n",
    "    - DoubleType\n",
    "    - FloatType\n",
    "    - ByteType\n",
    "    - IntegerType\n",
    "    - LongType\n",
    "    - ShortType\n",
    "    - ArrayType\n",
    "    - MapType\n",
    "    - StructField\n",
    "    - StructType\n",
    "    \n",
    "### Adding new columns to a dataframe or overwriting them\n",
    "\n",
    "You can use PySpark's .withColumn() method for both of these usecases. \n",
    "\n",
    "    Example (add new col): df.withColumn(\"double_age\",age*2)\n",
    "    Example (overwrite existing col): df.withColumn(\"age\",age*2)\n",
    "    \n",
    "Where the first value you pass in is the name of the new column and the second calls on the existing df column name you want to call on. You don't necessarily need to manipulate the variable here either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: date (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: boolean (nullable = true)\n",
      " |-- ratings_disabled: boolean (nullable = true)\n",
      " |-- video_error_or_removed: boolean (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE    2017-01-14   \n",
       "1  1ZAPwfrtAFY    2017-01-14   \n",
       "2  5qpjK5DgCt4    2017-01-14   \n",
       "3  puqaWrEC7tY    2017-01-14   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-13T11:00:04.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df= videos.withColumn(\"views\",videos[\"views\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"category_id\",videos[\"category_id\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"likes\",videos[\"likes\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"dislikes\",videos[\"dislikes\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"comment_count\",videos[\"comment_count\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"comments_disabled\",videos[\"comments_disabled\"].cast(BooleanType()))\\\n",
    "    .withColumn(\"ratings_disabled\",videos[\"ratings_disabled\"].cast(BooleanType()))\\\n",
    "    .withColumn(\"video_error_or_removed\",videos[\"video_error_or_removed\"].cast(BooleanType()))\\\n",
    "    .withColumn(\"trending_date\",to_date(videos.trending_date,\"yy.dd.mm\"))\n",
    "\n",
    "\n",
    "print(df.printSchema())\n",
    "df.limit(4).toPandas()\n",
    "\n",
    "#to_date is a method from pyspark.sql.types\n",
    "\n",
    "#.withColumn(\"publish_time\", to_timestamp(videos.publish_time, 'yyyy-MM-dd HH:mm:ss:ms'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming Columns**\n",
    "\n",
    "If you simply needed to rename a column you use also use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title_new</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>publish_time_2</th>\n",
       "      <th>publish_time_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "      <td>2017-11-13 17:13:01.000</td>\n",
       "      <td>2017-11-13 17:13:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "      <td>2017-11-13 07:30:00.000</td>\n",
       "      <td>2017-11-13 07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "      <td>2017-11-12 19:05:24.000</td>\n",
       "      <td>2017-11-12 19:05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "      <td>2017-11-13 11:00:04.000</td>\n",
       "      <td>2017-11-13 11:00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE    2017-01-14   \n",
       "1  1ZAPwfrtAFY    2017-01-14   \n",
       "2  5qpjK5DgCt4    2017-01-14   \n",
       "3  puqaWrEC7tY    2017-01-14   \n",
       "\n",
       "                                               title      channel_title_new  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-13T11:00:04.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "\n",
       "                                         description           publish_time_2  \\\n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  2017-11-13 17:13:01.000   \n",
       "1  One year after the presidential election, John...  2017-11-13 07:30:00.000   \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  2017-11-12 19:05:24.000   \n",
       "3  Today we find out if Link is a Nickelback amat...  2017-11-13 11:00:04.000   \n",
       "\n",
       "       publish_time_3  \n",
       "0 2017-11-13 17:13:01  \n",
       "1 2017-11-13 07:30:00  \n",
       "2 2017-11-12 19:05:24  \n",
       "3 2017-11-13 11:00:04  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Rename\n",
    "renamed = df.withColumnRenamed('channel_title','channel_title_new')\n",
    "renamed.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Data**\n",
    "\n",
    "Alright so we see that the publish_time variable could not be converted to a timestamp becuase it has those strange \"T\" and \"Z\" values between the date and the time. We essentially need to replace the \"T\" value with a space, and the Z value with nothing. There are a couple of ways we can do this, the first is regex which is short for regular expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex**\n",
    "\n",
    "Regex is used to replace or extract all substrings of the specified string value that match regexp with repetition.\n",
    "\n",
    "The syntax here is: regexp_replace(*str, pattern, replacement*)\n",
    "\n",
    "Regex is NOT super intuitive, so if you need a refresher on regex calls visit: \n",
    " - https://www.whoishostingthis.com/resources/regex/\n",
    " - https://docs.oracle.com/cd/B19306_01/server.102/b14200/ap_posix001.htm#BABJDBHB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               publish_time\n",
       "0  2017-11-13T17:13:01.000Z\n",
       "1  2017-11-13T07:30:00.000Z\n",
       "2  2017-11-12T19:05:24.000Z\n",
       "3  2017-11-13T11:00:04.000Z\n",
       "4  2017-11-12T18:01:41.000Z"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"publish_time\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, regexp_extract\n",
    "df = df.withColumn(\"publish_time_2\",regexp_replace(df.publish_time,\"T\",\" \"))\n",
    "df = df.withColumn(\"publish_time_2\",regexp_replace(df.publish_time_2,\"Z\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_time_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-13 17:13:01.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-13 07:30:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-12 19:05:24.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-13 11:00:04.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-12 18:01:41.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            publish_time_2\n",
       "0  2017-11-13 17:13:01.000\n",
       "1  2017-11-13 07:30:00.000\n",
       "2  2017-11-12 19:05:24.000\n",
       "3  2017-11-13 11:00:04.000\n",
       "4  2017-11-12 18:01:41.000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"publish_time_2\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"publish_time_3\",to_timestamp(df.publish_time_2,\"yyyy-MM-dd HH:mm:ss.SSS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: date (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: boolean (nullable = true)\n",
      " |-- ratings_disabled: boolean (nullable = true)\n",
      " |-- video_error_or_removed: boolean (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- publish_time_2: string (nullable = true)\n",
      " |-- publish_time_3: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>publish_time_2</th>\n",
       "      <th>real_publish_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "      <td>2017-11-13 17:13:01.000</td>\n",
       "      <td>2017-11-13 17:13:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "      <td>2017-11-13 07:30:00.000</td>\n",
       "      <td>2017-11-13 07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "      <td>2017-11-12 19:05:24.000</td>\n",
       "      <td>2017-11-12 19:05:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE    2017-01-14   \n",
       "1  1ZAPwfrtAFY    2017-01-14   \n",
       "2  5qpjK5DgCt4    2017-01-14   \n",
       "\n",
       "                                               title    channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE     CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...  LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...     Rudy Mancuso   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "\n",
       "                                         description           publish_time_2  \\\n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  2017-11-13 17:13:01.000   \n",
       "1  One year after the presidential election, John...  2017-11-13 07:30:00.000   \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  2017-11-12 19:05:24.000   \n",
       "\n",
       "    real_publish_time  \n",
       "0 2017-11-13 17:13:01  \n",
       "1 2017-11-13 07:30:00  \n",
       "2 2017-11-12 19:05:24  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming\n",
    "\n",
    "df = df.withColumnRenamed(\"publish_time_3\",\"real_publish_time\")\n",
    "\n",
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+-------------------+\n",
      "|publish_time            |publish_time_2         |real_publish_time  |\n",
      "+------------------------+-----------------------+-------------------+\n",
      "|2017-11-13T17:13:01.000Z|2017-11-13 17:13:01.000|2017-11-13 17:13:01|\n",
      "|2017-11-13T07:30:00.000Z|2017-11-13 07:30:00.000|2017-11-13 07:30:00|\n",
      "|2017-11-12T19:05:24.000Z|2017-11-12 19:05:24.000|2017-11-12 19:05:24|\n",
      "|2017-11-13T11:00:04.000Z|2017-11-13 11:00:04.000|2017-11-13 11:00:04|\n",
      "|2017-11-12T18:01:41.000Z|2017-11-12 18:01:41.000|2017-11-12 18:01:41|\n",
      "+------------------------+-----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check!\n",
    "df.select(\"publish_time\", \"publish_time_2\",\"real_publish_time\").show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translate Function**\n",
    "\n",
    "You could also use the Translate function here to do this, where the first set of values is what you are looking for and the second set is what you want to replace those values with respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_time</th>\n",
       "      <th>translate_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>2017-11-13 17:13:01.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>2017-11-13 07:30:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>2017-11-12 19:05:24.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>2017-11-13 11:00:04.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>2017-11-12 18:01:41.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               publish_time           translate_func\n",
       "0  2017-11-13T17:13:01.000Z  2017-11-13 17:13:01.000\n",
       "1  2017-11-13T07:30:00.000Z  2017-11-13 07:30:00.000\n",
       "2  2017-11-12T19:05:24.000Z  2017-11-12 19:05:24.000\n",
       "3  2017-11-13T11:00:04.000Z  2017-11-13 11:00:04.000\n",
       "4  2017-11-12T18:01:41.000Z  2017-11-12 18:01:41.000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "df.select(\"publish_time\",f.translate(f.col(\"publish_time\"),\"TZ\",\" \").alias(\"translate_func\")).limit(5).toPandas()\n",
    "\n",
    "#second parameter of .translate() is what you want to translate and the third is what you want them to become.\n",
    "#In this case, T and Z becomes \" \". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trim**\n",
    "\n",
    "One common function you've probably seen in almost any data processing tool including excel is the \"trim\" function which removes leading and trailing white space from a cell in various ways. Let's go ahead and do that with the title field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|title                                                         |\n",
      "+--------------------------------------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE                            |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)|\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons         |\n",
      "|Nickelback Lyrics: Real or Fake?                              |\n",
      "|I Dare You: GOING BALD!?                                      |\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trim\n",
    "\n",
    "\n",
    "# pyspark.sql.functions.trim(col) - Trim the spaces from both ends for the specified string column.\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = df.withColumn('title',trim(df.title)) # or rtrim/ltrim\n",
    "df.select(\"title\").show(5,False)\n",
    "\n",
    "# trim_ex = spark.createDataFrame([(' 2015-04-08 ',' 2015-05-10 ')], ['d1', 'd2']) # create a dataframe - notice the extra whitespaces in the date strings\n",
    "# trim_ex.show()\n",
    "# print(\"left trim\")\n",
    "# trim_ex.select('d1', ltrim(trim_ex.d1)).show()\n",
    "# print(\"right trim\")\n",
    "# trim_ex.select('d1', rtrim(trim_ex.d1)).show()\n",
    "# print(\"trim\")\n",
    "# trim_ex.select('d1', trim(trim_ex.d1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lower**\n",
    "\n",
    "Another common data cleaning technique is lower casing all values in a string. Here's how we could do that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|title                                                         |\n",
      "+--------------------------------------------------------------+\n",
      "|we want to talk about our marriage                            |\n",
      "|the trump presidency: last week tonight with john oliver (hbo)|\n",
      "|racist superman | rudy mancuso, king bach & lele pons         |\n",
      "|nickelback lyrics: real or fake?                              |\n",
      "|i dare you: going bald!?                                      |\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('title',lower(df.title)) # or rtrim/ltrim\n",
    "df.select(\"title\").show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case when**\n",
    "\n",
    "We can also use the classic sql \"case when\" clause to recode values. Let's say we wanted to create a categorical variable that told if the video had more likes than dislikes and visa versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option#1: select or withColumn() using when-otherwise\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>Favorability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    likes  dislikes Favorability\n",
       "0   57527      2966         Good\n",
       "1   97185      6146         Good\n",
       "2  146033      5339         Good\n",
       "3   10172       666         Good\n",
       "4  132235      1989         Good"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Case when\n",
    "#option1 : when-otherwise   :: choosing \"good\" video, measuring its quality through how many likes and dislikes they get and compare those two.\n",
    "print(\"Option#1: select or withColumn() using when-otherwise\")\n",
    "df.select(\"likes\",\"dislikes\",(when(df.likes>df.dislikes,\"Good\").when(df.likes<df.dislikes,\"Bad\").otherwise(\"Undetermined\")).alias(\"Favorability\")).limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option2: select or withColumn() using expr function\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>Favorability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    likes  dislikes Favorability\n",
       "0   57527      2966         GOOD\n",
       "1   97185      6146         GOOD\n",
       "2  146033      5339         GOOD\n",
       "3   10172       666         GOOD\n",
       "4  132235      1989         GOOD"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Option2\n",
    "#Expr\n",
    "print(\"Option2: select or withColumn() using expr function\")\n",
    "df.select(\"likes\",\"dislikes\",expr(\"CASE WHEN likes>dislikes THEN 'GOOD' WHEN dislikes > likes THEN 'Bad' ELSE 'Undetermined' END AS Favorability\")).limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 3: selectExpr() using SQL equivalent CASE expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>Favorability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    likes  dislikes Favorability\n",
       "0   57527      2966         GOOD\n",
       "1   97185      6146         GOOD\n",
       "2  146033      5339         GOOD\n",
       "3   10172       666         GOOD\n",
       "4  132235      1989         GOOD"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Option3\n",
    "print(\"Option 3: selectExpr() using SQL equivalent CASE expression\")\n",
    "\n",
    "df.selectExpr(\"likes\",\"dislikes\",\"CASE WHEN likes>dislikes THEN 'GOOD' WHEN dislikes > likes THEN 'Bad' ELSE 'Undetermined' END AS Favorability\").limit(5).toPandas()\n",
    "\n",
    "#Don't need to put 'expr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate**\n",
    "\n",
    "If you want to combine two variables together (given a separator) you can use the concatenate method. Let's say we wanted to combined all the text description variables of the videos here for a robust NLP exercise of some sort and we needed to have all the text in one colum to do that like this.\n",
    "\n",
    "    concat_ws(sep, *cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          channel_title\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat\n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight\n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso\n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning\n",
       "4                           I Dare You: GOING BALD!?               nigahiga"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"title\",df.channel_title).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+\n",
      "|content and creator                                                              |\n",
      "+---------------------------------------------------------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE by CaseyNeistat                               |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO) by LastWeekTonight|\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons by Rudy Mancuso            |\n",
      "|Nickelback Lyrics: Real or Fake? by Good Mythical Morning                        |\n",
      "|I Dare You: GOING BALD!? by nigahiga                                             |\n",
      "+---------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "df.select(concat_ws(' by ',df.title,df.channel_title).alias(\"content and creator\")).show(5,False)\n",
    "\n",
    "\n",
    "#concat_ws means \"concatenate things with separator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting data from Date and Timestamp variables**\n",
    "\n",
    "If you have the need to extract say the year or month from a date field, you can use PySpark's SQL function library like this. \n",
    "\n",
    "Note with this analysis we stumbled upon a date conversion discrepancy here. I'll leave fixing that for a hw problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+--------------------+\n",
      "|trending_date|year(trending_date)|month(trending_date)|\n",
      "+-------------+-------------------+--------------------+\n",
      "|   2017-01-14|               2017|                   1|\n",
      "|   2017-01-14|               2017|                   1|\n",
      "|   2017-01-14|               2017|                   1|\n",
      "|   2017-01-14|               2017|                   1|\n",
      "|   2017-01-14|               2017|                   1|\n",
      "+-------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month\n",
    "\n",
    "df.select(\"trending_date\",year(\"trending_date\"),month(\"trending_date\")).show(5)\n",
    "\n",
    "# Other options: dayofmonth, dayofweek, dayofyear, weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the Difference between two dates**\n",
    "\n",
    "If you want to calculate the time difference between two dates, you could use PySparks datediff function which returns the number of \"days\" from start to end.\n",
    "\n",
    "    datediff(end, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>real_publish_time</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>2017-11-13 17:13:01</td>\n",
       "      <td>0.830137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>2017-11-13 07:30:00</td>\n",
       "      <td>0.830137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>2017-11-12 19:05:24</td>\n",
       "      <td>0.827397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>2017-11-13 11:00:04</td>\n",
       "      <td>0.830137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>2017-11-12 18:01:41</td>\n",
       "      <td>0.827397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trending_date   real_publish_time      diff\n",
       "0    2017-01-14 2017-11-13 17:13:01  0.830137\n",
       "1    2017-01-14 2017-11-13 07:30:00  0.830137\n",
       "2    2017-01-14 2017-11-12 19:05:24  0.827397\n",
       "3    2017-01-14 2017-11-13 11:00:04  0.830137\n",
       "4    2017-01-14 2017-11-12 18:01:41  0.827397"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff\n",
    "\n",
    "df.select(\"trending_date\",\"real_publish_time\",(datediff(df.real_publish_time,df.trending_date)/365).alias(\"diff\")).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split a string around a pattern**\n",
    "\n",
    "If you ever need to split a string on a pattern (where the pattern is a regex), you could use PySparks split function. You could actually use this for tokenizing text which is an NLP function that we'll get into later.\n",
    "\n",
    "    df.select(split(str, pattern))\n",
    "    \n",
    "*Note that this will create an array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|title                             |\n",
      "+----------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE|\n",
      "+----------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split a string around pattern (pattern is a regular expression).\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "df.select(\"title\").show(1,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-------------------------------------------------------------------------+\n",
      "|title                                                         |new                                                                      |\n",
      "+--------------------------------------------------------------+-------------------------------------------------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE                            |[WE, WANT, TO, TALK, ABOUT, OUR, MARRIAGE]                               |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)|[The, Trump, Presidency:, Last, Week, Tonight, with, John, Oliver, (HBO)]|\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons         |[Racist, Superman, |, Rudy, Mancuso,, King, Bach, &, Lele, Pons]         |\n",
      "|Nickelback Lyrics: Real or Fake?                              |[Nickelback, Lyrics:, Real, or, Fake?]                                   |\n",
      "|I Dare You: GOING BALD!?                                      |[I, Dare, You:, GOING, BALD!?]                                           |\n",
      "+--------------------------------------------------------------+-------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array = df.select('title',split(df.title, ' ').alias('new'))\n",
    "array.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with Arrays**\n",
    "\n",
    "    df.select(array_contains(df.variable, \"marriage\"))\n",
    "\n",
    "*note this is only available in pyspark 2.4+* \n",
    "    \n",
    "\n",
    " - .array(*cols)   -   Creates a new array column.\n",
    " - .array_contains(col, value)  - Collection function: returns null if the array is null, true if the array contains the given value, and false otherwise.\n",
    " - .array_distinct(col) - Collection function: removes duplicate values from the array. :param col: name of column or expression\n",
    " - .array_except(col1, col2) - Collection function: returns an array of the elements in col1 but not in col2, without duplicates.\n",
    " - .array_intersect(col1, col2) - Collection function: returns an array of the elements in the intersection of col1 and col2, without duplicates.\n",
    " - .array_join(col, delimiter, null_replacement=None) - Concatenates the elements of column using the delimiter. Null values are replaced with null_replacement if set, otherwise they are ignored.\n",
    " - .array_max(col) - Collection function: returns the maximum value of the array.\n",
    " - .array_min(col) - Collection function: returns the minimum value of the array.\n",
    " - .array_position(col, value) - Collection function: Locates the position of the first occurrence of the given value in the given array. Returns null if either of the arguments are null.\n",
    " - .array_remove(col, element)- Collection function: Remove all elements that equal to element from the given array.\n",
    " - .array_repeat(col, count) - Collection function: creates an array containing a column repeated count times.\n",
    " - .array_sort(col) - Collection function: sorts the input array in ascending order. The elements of the input array must be orderable. Null elements will be placed at the end of the returned array.\n",
    " - .array_union(col1, col2) - Collection function: returns an array of the elements in the union of col1 and col2, without duplicates.\n",
    " - .arrays_overlap(a1, a2) - Collection function: returns true if the arrays contain any common non-null element; if not, returns null if both the arrays are non-empty and any of them contains a null element; returns false otherwise.\n",
    " - .arrays_zip(*cols)[source] - Collection function: Returns a merged array of structs in which the N-th struct contains all N-th values of input arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----------------------------+\n",
      "|title                                                         |array_contains(new, MARRIAGE)|\n",
      "+--------------------------------------------------------------+-----------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE                            |true                         |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)|false                        |\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons         |false                        |\n",
      "|Nickelback Lyrics: Real or Fake?                              |false                        |\n",
      "|I Dare You: GOING BALD!?                                      |false                        |\n",
      "+--------------------------------------------------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check whether arrays in a row contains a certin string\n",
    "array.select(\"title\",array_contains(array.new,\"MARRIAGE\")).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-------------------------------------+\n",
      "|title                                                         |array_contains(title_array, marriage)|\n",
      "+--------------------------------------------------------------+-------------------------------------+\n",
      "|WE WANT TO TALK ABOUT OUR MARRIAGE                            |false                                |\n",
      "|The Trump Presidency: Last Week Tonight with John Oliver (HBO)|false                                |\n",
      "|Racist Superman | Rudy Mancuso, King Bach & Lele Pons         |false                                |\n",
      "|Nickelback Lyrics: Real or Fake?                              |false                                |\n",
      "|I Dare You: GOING BALD!?                                      |false                                |\n",
      "+--------------------------------------------------------------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------------------------------------------------------------+\n",
      "|array_distinct(title_array)                                              |\n",
      "+-------------------------------------------------------------------------+\n",
      "|[WE, WANT, TO, TALK, ABOUT, OUR, MARRIAGE]                               |\n",
      "|[The, Trump, Presidency:, Last, Week, Tonight, with, John, Oliver, (HBO)]|\n",
      "|[Racist, Superman, |, Rudy, Mancuso,, King, Bach, &, Lele, Pons]         |\n",
      "|[Nickelback, Lyrics:, Real, or, Fake?]                                   |\n",
      "|[I, Dare, You:, GOING, BALD!?]                                           |\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------------------------------------------------------------+\n",
      "|array_remove(title_array, WE)                                            |\n",
      "+-------------------------------------------------------------------------+\n",
      "|[WANT, TO, TALK, ABOUT, OUR, MARRIAGE]                                   |\n",
      "|[The, Trump, Presidency:, Last, Week, Tonight, with, John, Oliver, (HBO)]|\n",
      "|[Racist, Superman, |, Rudy, Mancuso,, King, Bach, &, Lele, Pons]         |\n",
      "|[Nickelback, Lyrics:, Real, or, Fake?]                                   |\n",
      "|[I, Dare, You:, GOING, BALD!?]                                           |\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "array_df = df.select(\"title\",split(df.title, ' ').alias('title_array'))\n",
    "\n",
    "array_df.select(\"title\",array_contains(array_df.title_array, \"marriage\")).show(5, False)\n",
    "\n",
    "#get rid of repeated values\n",
    "array_df.select(array_distinct(array_df.title_array)).show(5, False)\n",
    "\n",
    "# Remove certian values\n",
    "array_df.select(array_remove(array_df.title_array, \"WE\")).show(5, False)\n",
    "#This is case-sensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Functions\n",
    "\n",
    "Functions, as you know them if you are familiar with Python, work a bit differently in Pyspark because it operates on a **cluster**. \n",
    "\n",
    "If you define a function the traditional Python way in PySpark, you will NOT recieve an error message but the call will not distribute on all nodes. So it will run slower. \n",
    "\n",
    "**So to convert a Python function to what's called a user defined function (UDF) in PySpark. This is what you do.**\n",
    "\n",
    "*Note: keep in mind that a function will not work on a column with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "#Let's say we want to create square function that goes through all the columns and values \n",
    "def square(x):\n",
    "    return int(x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_udf = udf(lambda z: square(z), IntegerType())\n",
    "#pass function in a form of square(z) where z is scalar value from the Dataframe\n",
    "#and its type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|dislikes|likes_sq|\n",
      "+--------+--------+\n",
      "|    2966| 8797156|\n",
      "|    6146|37773316|\n",
      "|    5339|28504921|\n",
      "|     666|  443556|\n",
      "|    1989| 3956121|\n",
      "|     511|  261121|\n",
      "|    2445| 5978025|\n",
      "|     778|  605284|\n",
      "|     119|   14161|\n",
      "|    1363| 1857769|\n",
      "|      25|     625|\n",
      "|     303|   91809|\n",
      "|    1333| 1776889|\n",
      "|    1171| 1371241|\n",
      "|     246|   60516|\n",
      "|      52|    2704|\n",
      "|     638|  407044|\n",
      "|      53|    2809|\n",
      "|      36|    1296|\n",
      "|     191|   36481|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('dislikes',square_udf('dislikes').alias('likes_sq')).where(col('dislikes').isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 605, in main\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 597, in process\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 223, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 212, in _batched\n    for item in iterator:\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in mapper\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in <genexpr>\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 90, in <lambda>\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-93-f30e5c177d48>\", line 1, in <lambda>\n  File \"<ipython-input-92-071623db5c99>\", line 6, in square\nTypeError: unsupported operand type(s) for ** or pow(): 'NoneType' and 'int'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-0896c0760f80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#what if with no .where(col('dislikes').isNotNull()) ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dislikes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msquare_udf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dislikes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'likes_sq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mcolumn_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    594\u001b[0m         \"\"\"\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(e)\u001b[0m\n",
      "\u001b[1;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 605, in main\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 597, in process\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 223, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 212, in _batched\n    for item in iterator:\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in mapper\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in <genexpr>\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 90, in <lambda>\n  File \"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-93-f30e5c177d48>\", line 1, in <lambda>\n  File \"<ipython-input-92-071623db5c99>\", line 6, in square\nTypeError: unsupported operand type(s) for ** or pow(): 'NoneType' and 'int'\n"
     ]
    }
   ],
   "source": [
    "#what if with no .where(col('dislikes').isNotNull()) ?\n",
    "df.select('dislikes',square_udf('dislikes').alias('likes_sq')).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not all function behaves like the above one.\n",
    "\n",
    "- It is only if you're trying to iterate over a column in the dataframe. \n",
    "\n",
    "- For example, if you are passing \"whole\" dataframe into a function, you don't need UDF. \n",
    "\n",
    "- so, again, this is only on columns with dataframe. \n",
    "    - There is function that you need to manipulate a certain column in your dataframe that's not available in SQLfunction library or anywhere else, then you might wanna go for UDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's all folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
