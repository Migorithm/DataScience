{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93869576",
   "metadata": {},
   "source": [
    "### Spark Dataframe\n",
    "\n",
    "#### Brief history\n",
    "- Spark started out storing data in what they called an \"RDD\" which required syntax that was not intuitive.\n",
    "\n",
    "- Spark 2.0 and higher now no longer maintains RDD syntax and exclusivly uses DataFrame syntax which is easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d0ba0",
   "metadata": {},
   "source": [
    "#### Reading in DataFrames\n",
    "\n",
    "- Supports professional formats like JSON files, Parquet files, Hive table\n",
    "\n",
    "- From local file system, HDFS, cloud storage(S3) or external RBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9066b7",
   "metadata": {},
   "source": [
    "#### Partitioning data in pyspark\n",
    "\n",
    "- Pyspark offers build in libarary to read and write \"partitioned\" datasets which is preferred storage method that divides up the dataset into more than one part.\n",
    "\n",
    "- When it comes to Big data management, the preferred method is what's called parquet files(compression type, even smaller than csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b34500",
   "metadata": {},
   "source": [
    "#### Showing results vs Collecting results.\n",
    "\n",
    "- **show()** gives you a preview (like python pandas.DataFrame.head())\n",
    "\n",
    "- **collect()**\n",
    "    - it's done more addtional processing \n",
    "    - more computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19162677",
   "metadata": {},
   "source": [
    "#### Spark User Defined Functions (UDF's)\n",
    "\n",
    "- In pyspark, not all your python functions will be able to iterate over a distributed dataframe. \n",
    "- If your  def is designed to iterate over a column in a dataframe, you need to use a Spark UDF. \n",
    "\n",
    "\n",
    "    def square_float(x):\n",
    "        return float(x**2)\n",
    "    square_udf_float2 = udf(lambda z : square_float(z), FloatType())\n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5071ce7",
   "metadata": {},
   "source": [
    "#### Spark User Defined Functions (UDF's)2\n",
    "\n",
    "    def Indexer(df,indenpendent_var):\n",
    "        renamed = df.withColumn(\"label_str\",df[dependent_var].cast(StringType()))\n",
    "        indexer = StringIndexer(inputCol=\"label_str\",outputCol=\"label\")\n",
    "        indexed = indexer.fit(renamed).transform(renamed)\n",
    "        return indexed\n",
    "        \n",
    "    final_data=Indexer(df,input_columns,dependent_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e62d02",
   "metadata": {},
   "source": [
    "### Reading and Writing in PySpark\n",
    "\n",
    "**Objectives:**\n",
    "- Reading in Data\n",
    "- Partioned Files\n",
    "- Validating Data\n",
    "- Specifying Data Types\n",
    "- Writing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8af2be",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cdc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HADOOP_HOME']=r\"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\"\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Java\\jdk1.8.0_291\"\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f448803a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'echosys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-acc8ba68eb12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"echosys\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[1;31m# raise KeyError with the original key value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'echosys'"
     ]
    }
   ],
   "source": [
    "os.environ[\"echosys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb45704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-JOJHKCD:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ReadWriteVal</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2004213eee0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(\"C:\\encore_migo\\spark\\spark-3.0.3-bin-hadoop2.7\") \n",
    "#this is not comparable to MacOS, it finds your local pyspark instance within your local drives automatically \n",
    "\n",
    "\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#SparkSession like an object\n",
    "spark = SparkSession.builder.appName(\"ReadWriteVal\").getOrCreate() #Note that it is CamelCase\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc523c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above link \"Spark UI\" will open up Spark Job page. \n",
    "# you can check out how long the job takes and etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389c7618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check how many cores you have \n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff385f",
   "metadata": {},
   "source": [
    "#### DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b3de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "path =\"data/Read_Write_Validate_Datasets/\"\n",
    "\n",
    "students = spark.read.csv(path + \"students.csv\",inferSchema=True,header=True)\n",
    "\n",
    "#inferSchema :: it is to let spark figure out datatype of dataframe. Sometimes it's accurate, sometimes, not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2c6c4",
   "metadata": {},
   "source": [
    "#### Preview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6a1de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put limit and convert that into Pandas \n",
    "students.limit(4).toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e6e2c",
   "metadata": {},
   "source": [
    "#### How to read in Parquet files?\n",
    "\n",
    "- Parquet data type is the most common in big data world. \n",
    "- it is the most compact file storage method even better than zip files and csvs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05e3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet = spark.read.parquet(path+\"users1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b7b6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration_dttm</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>cc</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-03 16:55:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>ajordan0@com.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.197.201.2</td>\n",
       "      <td>6759521864920116</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3/8/1971</td>\n",
       "      <td>49756.53</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>1E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-04 02:04:03</td>\n",
       "      <td>2</td>\n",
       "      <td>Albert</td>\n",
       "      <td>Freeman</td>\n",
       "      <td>afreeman1@is.gd</td>\n",
       "      <td>Male</td>\n",
       "      <td>218.111.175.34</td>\n",
       "      <td></td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/16/1968</td>\n",
       "      <td>150280.17</td>\n",
       "      <td>Accountant IV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-03 10:09:31</td>\n",
       "      <td>3</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>emorgan2@altervista.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.161.136.94</td>\n",
       "      <td>6767119071901597</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2/1/1960</td>\n",
       "      <td>144972.51</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-03 09:36:21</td>\n",
       "      <td>4</td>\n",
       "      <td>Denise</td>\n",
       "      <td>Riley</td>\n",
       "      <td>driley3@gmpg.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>140.35.109.83</td>\n",
       "      <td>3576031598965625</td>\n",
       "      <td>China</td>\n",
       "      <td>4/8/1997</td>\n",
       "      <td>90263.05</td>\n",
       "      <td>Senior Cost Accountant</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    registration_dttm  id first_name last_name                    email  \\\n",
       "0 2016-02-03 16:55:29   1     Amanda    Jordan         ajordan0@com.com   \n",
       "1 2016-02-04 02:04:03   2     Albert   Freeman          afreeman1@is.gd   \n",
       "2 2016-02-03 10:09:31   3     Evelyn    Morgan  emorgan2@altervista.org   \n",
       "3 2016-02-03 09:36:21   4     Denise     Riley         driley3@gmpg.org   \n",
       "\n",
       "   gender      ip_address                cc    country  birthdate     salary  \\\n",
       "0  Female     1.197.201.2  6759521864920116  Indonesia   3/8/1971   49756.53   \n",
       "1    Male  218.111.175.34                       Canada  1/16/1968  150280.17   \n",
       "2  Female    7.161.136.94  6767119071901597     Russia   2/1/1960  144972.51   \n",
       "3  Female   140.35.109.83  3576031598965625      China   4/8/1997   90263.05   \n",
       "\n",
       "                    title comments  \n",
       "0        Internal Auditor    1E+02  \n",
       "1           Accountant IV           \n",
       "2     Structural Engineer           \n",
       "3  Senior Cost Accountant           "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcd789",
   "metadata": {},
   "source": [
    "#### How to read several files at once?\n",
    "\n",
    "- user files have been stored in each of the different files (user1.parquet, user2.parquet...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bc19e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration_dttm</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>cc</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-03 16:55:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>ajordan0@com.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.197.201.2</td>\n",
       "      <td>6759521864920116</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3/8/1971</td>\n",
       "      <td>49756.53</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>1E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-04 02:04:03</td>\n",
       "      <td>2</td>\n",
       "      <td>Albert</td>\n",
       "      <td>Freeman</td>\n",
       "      <td>afreeman1@is.gd</td>\n",
       "      <td>Male</td>\n",
       "      <td>218.111.175.34</td>\n",
       "      <td></td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/16/1968</td>\n",
       "      <td>150280.17</td>\n",
       "      <td>Accountant IV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-03 10:09:31</td>\n",
       "      <td>3</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>emorgan2@altervista.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.161.136.94</td>\n",
       "      <td>6767119071901597</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2/1/1960</td>\n",
       "      <td>144972.51</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-03 09:36:21</td>\n",
       "      <td>4</td>\n",
       "      <td>Denise</td>\n",
       "      <td>Riley</td>\n",
       "      <td>driley3@gmpg.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>140.35.109.83</td>\n",
       "      <td>3576031598965625</td>\n",
       "      <td>China</td>\n",
       "      <td>4/8/1997</td>\n",
       "      <td>90263.05</td>\n",
       "      <td>Senior Cost Accountant</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-03 14:05:31</td>\n",
       "      <td>5</td>\n",
       "      <td>Carlos</td>\n",
       "      <td>Burns</td>\n",
       "      <td>cburns4@miitbeian.gov.cn</td>\n",
       "      <td></td>\n",
       "      <td>169.113.235.40</td>\n",
       "      <td>5602256255204850</td>\n",
       "      <td>South Africa</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    registration_dttm  id first_name last_name                     email  \\\n",
       "0 2016-02-03 16:55:29   1     Amanda    Jordan          ajordan0@com.com   \n",
       "1 2016-02-04 02:04:03   2     Albert   Freeman           afreeman1@is.gd   \n",
       "2 2016-02-03 10:09:31   3     Evelyn    Morgan   emorgan2@altervista.org   \n",
       "3 2016-02-03 09:36:21   4     Denise     Riley          driley3@gmpg.org   \n",
       "4 2016-02-03 14:05:31   5     Carlos     Burns  cburns4@miitbeian.gov.cn   \n",
       "\n",
       "   gender      ip_address                cc       country  birthdate  \\\n",
       "0  Female     1.197.201.2  6759521864920116     Indonesia   3/8/1971   \n",
       "1    Male  218.111.175.34                          Canada  1/16/1968   \n",
       "2  Female    7.161.136.94  6767119071901597        Russia   2/1/1960   \n",
       "3  Female   140.35.109.83  3576031598965625         China   4/8/1997   \n",
       "4          169.113.235.40  5602256255204850  South Africa              \n",
       "\n",
       "      salary                   title comments  \n",
       "0   49756.53        Internal Auditor    1E+02  \n",
       "1  150280.17           Accountant IV           \n",
       "2  144972.51     Structural Engineer           \n",
       "3   90263.05  Senior Cost Accountant           \n",
       "4        NaN                                   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Walking a Directory Tree\n",
    "\n",
    "import os\n",
    "lst = []\n",
    "for folder_name, subfolders, filenames in os.walk(path):\n",
    "    for i in filenames:\n",
    "        if i.startswith(\"users\"):\n",
    "            lst.append(folder_name+i)\n",
    "\n",
    "users = spark.read.parquet(*lst)\n",
    "users.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c8ac8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration_dttm</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>cc</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-03 16:55:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>ajordan0@com.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.197.201.2</td>\n",
       "      <td>6759521864920116</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3/8/1971</td>\n",
       "      <td>49756.53</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>1E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-04 02:04:03</td>\n",
       "      <td>2</td>\n",
       "      <td>Albert</td>\n",
       "      <td>Freeman</td>\n",
       "      <td>afreeman1@is.gd</td>\n",
       "      <td>Male</td>\n",
       "      <td>218.111.175.34</td>\n",
       "      <td></td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/16/1968</td>\n",
       "      <td>150280.17</td>\n",
       "      <td>Accountant IV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-03 10:09:31</td>\n",
       "      <td>3</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>emorgan2@altervista.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.161.136.94</td>\n",
       "      <td>6767119071901597</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2/1/1960</td>\n",
       "      <td>144972.51</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    registration_dttm  id first_name last_name                    email  \\\n",
       "0 2016-02-03 16:55:29   1     Amanda    Jordan         ajordan0@com.com   \n",
       "1 2016-02-04 02:04:03   2     Albert   Freeman          afreeman1@is.gd   \n",
       "2 2016-02-03 10:09:31   3     Evelyn    Morgan  emorgan2@altervista.org   \n",
       "\n",
       "   gender      ip_address                cc    country  birthdate     salary  \\\n",
       "0  Female     1.197.201.2  6759521864920116  Indonesia   3/8/1971   49756.53   \n",
       "1    Male  218.111.175.34                       Canada  1/16/1968  150280.17   \n",
       "2  Female    7.161.136.94  6767119071901597     Russia   2/1/1960  144972.51   \n",
       "\n",
       "                 title comments  \n",
       "0     Internal Auditor    1E+02  \n",
       "1        Accountant IV           \n",
       "2  Structural Engineer           "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose 1,3file\n",
    "\n",
    "user1_3 = spark.read.parquet(lst[0],lst[2])\n",
    "user1_3.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678819d",
   "metadata": {},
   "source": [
    "#### On AWS..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d64484",
   "metadata": {},
   "source": [
    "**Example)**\n",
    "\n",
    "    bucket = \"my_bucket\"\n",
    "    key1 = \"partition_test/Table1/CREATED_YEAR=2015/*\"\n",
    "    key2 = \"partition_test/Table1/CREATED_YEAR=2017/*\"\n",
    "    key3 = \"partition_test/Table1/CREATED_YEAR=2018/*\"\n",
    "\n",
    "    test_df = spark.read.parquet('s3://'+bucket+'/'+key1,\n",
    "                                 's3://'+bucket+'/'+key2,\n",
    "                                 's3://'+bucket+'/'+key3)\n",
    "\n",
    "    test_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4caef",
   "metadata": {},
   "source": [
    "###  Validating Data in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c31f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check out the schema (data time, nullable...)\n",
    "students.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305a2e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'race/ethnicity',\n",
       " 'parental level of education',\n",
       " 'lunch',\n",
       " 'test preparation course',\n",
       " 'math score',\n",
       " 'reading score',\n",
       " 'writing score']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out columns\n",
    "students.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66932c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntegerType"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wanna see specific datatype ?\n",
    "students.schema['math score'].dataType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0c57a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+\n",
      "|summary|math score|reading score|\n",
      "+-------+----------+-------------+\n",
      "|  count|      1000|         1000|\n",
      "|    min|         0|           17|\n",
      "|    max|       100|          100|\n",
      "+-------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To get summary\n",
    "students.select(\"math score\",\"reading score\").summary(\"count\",\"min\",\"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63bf437",
   "metadata": {},
   "source": [
    "### How to specify data types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02843d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642ae421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To set schema for dataframe.\n",
    "#StructField(fieldName,Type_of_field,If_Nullable)\n",
    "\n",
    "data_schema = [StructField(\"name\",StringType(),True),\n",
    "              StructField(\"email\",StringType(),True),\n",
    "              StructField(\"city\",StringType(),True),\n",
    "              StructField(\"mac\",StringType(),True),\n",
    "              StructField(\"timestamp\",DateType(),True),\n",
    "              StructField(\"creditcard\",StringType(),True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6df6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "075ea118",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = spark.read.json(path+\"people.json\",schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aff5719e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>mac</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>creditcard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keeley Bosco</td>\n",
       "      <td>katlyn@jenkinsmaggio.net</td>\n",
       "      <td>Lake Gladysberg</td>\n",
       "      <td>08:fd:0b:cd:77:f7</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1228-1221-1221-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rubye Jerde</td>\n",
       "      <td>juvenal@johnston.name</td>\n",
       "      <td>None</td>\n",
       "      <td>90:4d:fa:42:63:a2</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1228-1221-1221-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss Darian Breitenberg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>f9:0e:d3:40:cb:e9</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                     email             city  \\\n",
       "0                     None                      None             None   \n",
       "1             Keeley Bosco  katlyn@jenkinsmaggio.net  Lake Gladysberg   \n",
       "2              Rubye Jerde     juvenal@johnston.name             None   \n",
       "3  Miss Darian Breitenberg                      None             None   \n",
       "\n",
       "                 mac   timestamp           creditcard  \n",
       "0               None        None                 None  \n",
       "1  08:fd:0b:cd:77:f7  2015-04-25  1228-1221-1221-1431  \n",
       "2  90:4d:fa:42:63:a2  2015-04-25  1228-1221-1221-1431  \n",
       "3  f9:0e:d3:40:cb:e9  2015-04-25                 None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8fc7350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- mac: string (nullable = true)\n",
      " |-- timestamp: date (nullable = true)\n",
      " |-- creditcard: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check out the schema again!\n",
    "people.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee67c9",
   "metadata": {},
   "source": [
    "#### Later on, I'll have to see some examples where I can actually change data types after I've already read in a file.\n",
    "\n",
    "- Case1, if dataFrame has so many fields that I don't wanna bother going through\n",
    "\n",
    "- Case2, when you just want change one or two column types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7de088",
   "metadata": {},
   "source": [
    "### Writing in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dafee44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[gender: string, race/ethnicity: string, parental level of education: string, lunch: string, test preparation course: string, math score: int, reading score: int, writing score: int]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db19c9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'save mode\\n- \"error\"  :: when saving a DataFrame, if data already exists, an exception is expected to be thrown.\\n- \"append\" :: if data/table already exists, contents of the DataFrame are expected to be appended to existing data.\\n- \"overwrite\" :: existing data is expected to be overwritten \\n- \"ignore\" ::, the save operation is expected not to save the contents of the DataFrame and not to change the existing data.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save mode\n",
    "- \"error\"  :: when saving a DataFrame, if data already exists, an exception is expected to be thrown.\n",
    "- \"append\" :: if data/table already exists, contents of the DataFrame are expected to be appended to existing data.\n",
    "- \"overwrite\" :: existing data is expected to be overwritten \n",
    "- \"ignore\" ::, the save operation is expected not to save the contents of the DataFrame and not to change the existing data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# students.write.mode(\"overwrite\").csv('write_test.csv')\n",
    "\n",
    "# user1_3.write.mode(\"overwrite\").partitionBy(\"gender\").parquet(\"part_parquet/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7b489e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| fruit|quant|\n",
      "+------+-----+\n",
      "|  Pear|   10|\n",
      "|Orange|   10|\n",
      "| Peach|    5|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#custom dataframe\n",
    "\n",
    "values =[(\"Pear\",10),(\"Orange\",10),(\"Peach\",5)]\n",
    "df = spark.createDataFrame(values,['fruit','quant'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a442f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
